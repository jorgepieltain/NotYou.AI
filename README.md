# ğŸ§  NotYou.AI

Modular and autonomous system for knowledge processing and creative content generation based on AI agents.

## ğŸ§± Architecture

- **n8n** â€“ Workflow orchestrator and data entry  
- **Supabase** â€“ Relational database and vector store  
- **LangGraph** â€“ Agent coordination with shared memory  
- **FastAPI** â€“ API for services like retriever, summary, clustering...  
- **Docker Compose** â€“ Controlled and reproducible environment  
- **Editable Python package** â€“ Enables clean imports, CLI scripts, and microservices

---

## ğŸ“¦ Included Services

| Service               | Folder                    | Port  | Current Status      |
|----------------------|---------------------------|-------|---------------------|
| ğŸŸ¢ n8n                | `/n8n`                    | 5678  | âœ… Active            |
| ğŸ”µ cluster-service-pro| `/cluster-service-pro`    | 8800  | âœ… Active            |
| ğŸŸ  cluster-interpreter| `/cluster_interpreter`    | 8500  | ğŸ”§ In development    |
| ğŸ’¤ pca-service        | `/pca-service`            | 8600  | ğŸ’¤ Ready             |
| ğŸ’¤ multi-cluster      | `/multi-cluster-service`  | 8700  | ğŸ’¤ Ready             |

---

## ğŸ’¡ Local Installation (recommended for development)

From the root of the project:

```bash
pip install -e .
```

This allows any agent, script or service to import from `cluster_interpreter` without modifying `sys.path`.

Example:

```bash
python cluster_interpreter/agents/retriever_agent/nodes/coverage_checker.py
```

---

## ğŸš€ Running the System with Docker

From the root folder:

```bash
docker compose up --build
```

### ğŸ” Required Variables

Create a `.env` file at the root with:

```env
OPENAI_API_KEY=
SUPABASE_URL=
SUPABASE_KEY=
POSTGRES_URL=
```

Use `.env.example` as a reference.

---

## ğŸ“ Project Structure

```
AGENTE_IA/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ setup.cfg
â”œâ”€â”€ .env
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ cluster_interpreter/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ retriever_agent/
â”‚   â”‚   â”‚   â”œâ”€â”€ nodes/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ schema_loader.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ coverage_checker.py
â”‚   â”‚   â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ retriever_prompt.txt
â”‚   â”‚   â”‚   â””â”€â”€ graph.py
â”‚   â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ schema_definitions.json
â”‚   â”‚   â””â”€â”€ schema_links.json
â”œâ”€â”€ cluster-service-pro/
â”œâ”€â”€ n8n/
â”œâ”€â”€ pca-service/
â””â”€â”€ multi-cluster-service/
```

---

## ğŸ§  Notes

- Each service has its own `Dockerfile`.
- The `.env` file is shared across containers and local scripts.
- Scripts can be tested locally or invoked from `n8n`/LangGraph.
- The architecture is modular and phase-extensible.
- Clean Python packaging ensures imports never fail across tools, agents or services.
